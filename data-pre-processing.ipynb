{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0caa1a0f",
   "metadata": {},
   "source": [
    "### Intalling libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e34be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d239cc03",
   "metadata": {},
   "source": [
    "### Column description\n",
    "\n",
    "| Variável \t| Descrição \t|\n",
    "|:-:\t|:-\t|\n",
    "| PassangerID \t| ID de identificação do passageiro(a) \t|\n",
    "| Survived \t| se o passageiro(a) sobreviveu (0 = não, 1 = sim) \t|\n",
    "| Pclass \t| classe do passageiro:<br>     * **1 = primeira**,<br>     * **2 = segunda**,<br>     * **3 = terceira** \t|\n",
    "| name \t| nome do passageiro(a) \t|\n",
    "| sex \t| sexo do passageiro(a) \t|\n",
    "| age \t| idade do passageiro(a) \t|\n",
    "| Sibsp \t| número de irmão(ãs)/esposo(a) à bordo \t|\n",
    "| Parch \t| número de pais/filhos(as) à bordo \t|\n",
    "| Ticket \t| número da passagem \t|\n",
    "| Fare \t| preço da passagem \t|\n",
    "| Cabin \t| cabine \t|\n",
    "| Embarked \t| local que o passageiro(a) embarcou:<br>     * **C = Cherboug**,<br>     * **Q = Queenstown**,<br>     * **S = Southamption** \t|\n",
    "| WikiId \t| ID de identificação do passageiro(a) segundo Wikipedia \t|\n",
    "| Name_wiki \t| nome do passageiro(a) \t|\n",
    "| Age_wiki \t| idade do passageiro(a) \t|\n",
    "| Hometown \t| cidade de nascimento do passageiro(a) \t|\n",
    "| Boarded \t| cidade de embarque \t|\n",
    "| Destination \t| destino da viagem \t|\n",
    "| Lifeboat \t| identificação do bote salva-vidas \t|\n",
    "| Body \t| número de identificação do corpo \t|\n",
    "\n",
    "\n",
    "<font color='red'>**IMPORTANT**</font>\n",
    "\n",
    "The new features (the ones after 'Embarked') are very similar to the original ones but they are more up-to-date and have much fewer missing values. Therefore, users can decide on the preferred features themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696865d3",
   "metadata": {},
   "source": [
    "### Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c7b8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# data visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import (\n",
    "    jointplot,\n",
    "    pairplot,\n",
    "    boxplot,\n",
    "    heatmap\n",
    ")\n",
    "from yellowbrick.features import (\n",
    "    JointPlotVisualizer,\n",
    "    Rank2D, \n",
    "    RadViz,\n",
    "    ParallelCoordinates\n",
    ")\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import(\n",
    "    radviz\n",
    ")\n",
    "\n",
    "from collections import (\n",
    "    Counter,\n",
    ")\n",
    "\n",
    "import janitor as jn\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# missing values\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.impute import (\n",
    "    SimpleImputer\n",
    ")\n",
    "\n",
    "# machine learning models\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    preprocessing,\n",
    "    tree,\n",
    "    impute,\n",
    "    model_selection,\n",
    "    preprocessing\n",
    ")\n",
    "\n",
    "from sklearn.dummy import (\n",
    "    DummyClassifier\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split\n",
    ")\n",
    "\n",
    "from sklearn.experimental import (\n",
    "    enable_iterative_imputer\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression\n",
    ")\n",
    "\n",
    "from sklearn.tree import (\n",
    "    DecisionTreeClassifier\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import (\n",
    "    KNeighborsClassifier\n",
    ")\n",
    "\n",
    "from sklearn.naive_bayes import (\n",
    "    GaussianNB\n",
    ")\n",
    "\n",
    "from sklearn.svm import (\n",
    "    SVC\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier\n",
    ")\n",
    "\n",
    "import xgboost\n",
    "\n",
    "# data model metrics\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "from yellowbrick.classifier import (\n",
    "    ConfusionMatrix\n",
    ")\n",
    "\n",
    "from yellowbrick.model_selection import (\n",
    "    LearningCurve\n",
    ")\n",
    "\n",
    "# data prep-model\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    learning_curve\n",
    ")\n",
    "\n",
    "# model deploy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e460a7d",
   "metadata": {},
   "source": [
    "### Reading the Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f47c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>WikiId</th>\n",
       "      <th>Name_wiki</th>\n",
       "      <th>Age_wiki</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Boarded</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Lifeboat</th>\n",
       "      <th>Body</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>691.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Bridgerule, Devon, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Qu'Appelle Valley, Saskatchewan, Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Cumings, Mrs. Florence Briggs (née Thayer)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>865.0</td>\n",
       "      <td>Heikkinen, Miss Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Jyväskylä, Finland</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>14?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Futrelle, Mrs. Lily May (née Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>627.0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Birmingham, West Midlands, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                 0.0       3   \n",
       "2                 1.0       1   \n",
       "3                 1.0       3   \n",
       "4                 1.0       1   \n",
       "5                 0.0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  WikiId  \\\n",
       "PassengerId                                                                   \n",
       "1                1      0         A/5 21171   7.2500   NaN        S   691.0   \n",
       "2                1      0          PC 17599  71.2833   C85        C    90.0   \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S   865.0   \n",
       "4                1      0            113803  53.1000  C123        S   127.0   \n",
       "5                0      0            373450   8.0500   NaN        S   627.0   \n",
       "\n",
       "                                              Name_wiki  Age_wiki  \\\n",
       "PassengerId                                                         \n",
       "1                               Braund, Mr. Owen Harris      22.0   \n",
       "2            Cumings, Mrs. Florence Briggs (née Thayer)      35.0   \n",
       "3                                 Heikkinen, Miss Laina      26.0   \n",
       "4                    Futrelle, Mrs. Lily May (née Peel)      35.0   \n",
       "5                              Allen, Mr. William Henry      35.0   \n",
       "\n",
       "                                       Hometown      Boarded  \\\n",
       "PassengerId                                                    \n",
       "1                    Bridgerule, Devon, England  Southampton   \n",
       "2                        New York, New York, US    Cherbourg   \n",
       "3                            Jyväskylä, Finland  Southampton   \n",
       "4                   Scituate, Massachusetts, US  Southampton   \n",
       "5            Birmingham, West Midlands, England  Southampton   \n",
       "\n",
       "                                         Destination Lifeboat Body  Class  \n",
       "PassengerId                                                                \n",
       "1            Qu'Appelle Valley, Saskatchewan, Canada      NaN  NaN    3.0  \n",
       "2                             New York, New York, US        4  NaN    1.0  \n",
       "3                                      New York City      14?  NaN    3.0  \n",
       "4                        Scituate, Massachusetts, US        D  NaN    1.0  \n",
       "5                                      New York City      NaN  NaN    3.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic_dataset.csv\", index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08aa73e",
   "metadata": {},
   "source": [
    "### Deleting _Class_ feature at the end\n",
    "We are deleting because is the same as _pclass_ (same result, same data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a06118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>WikiId</th>\n",
       "      <th>Name_wiki</th>\n",
       "      <th>Age_wiki</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Boarded</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Lifeboat</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>691.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Bridgerule, Devon, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Qu'Appelle Valley, Saskatchewan, Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Cumings, Mrs. Florence Briggs (née Thayer)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>865.0</td>\n",
       "      <td>Heikkinen, Miss Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Jyväskylä, Finland</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>14?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Futrelle, Mrs. Lily May (née Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>627.0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Birmingham, West Midlands, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>23.0</td>\n",
       "      <td>London, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>229.0</td>\n",
       "      <td>and maid, Doña Fermina Oliva y Ocana</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Madrid, Spain</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>Sæther, Mr. Simon Sivertsen</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Skaun, Sør-Trøndelag, Norway</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>Ware, Mr. Frederick William</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Greenwich, London, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>702.0</td>\n",
       "      <td>Butrus-Youssef, Master Makhkhul</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sar'al[81], Syria</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Detroit, Michigan, US</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                 0.0       3   \n",
       "2                 1.0       1   \n",
       "3                 1.0       3   \n",
       "4                 1.0       1   \n",
       "5                 0.0       3   \n",
       "...               ...     ...   \n",
       "1305              NaN       3   \n",
       "1306              NaN       1   \n",
       "1307              NaN       3   \n",
       "1308              NaN       3   \n",
       "1309              NaN       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "1305                                        Spector, Mr. Woolf    male   NaN   \n",
       "1306                              Oliva y Ocana, Dona. Fermina  female  39.0   \n",
       "1307                              Saether, Mr. Simon Sivertsen    male  38.5   \n",
       "1308                                       Ware, Mr. Frederick    male   NaN   \n",
       "1309                                  Peter, Master. Michael J    male   NaN   \n",
       "\n",
       "             SibSp  Parch              Ticket      Fare Cabin Embarked  \\\n",
       "PassengerId                                                              \n",
       "1                1      0           A/5 21171    7.2500   NaN        S   \n",
       "2                1      0            PC 17599   71.2833   C85        C   \n",
       "3                0      0    STON/O2. 3101282    7.9250   NaN        S   \n",
       "4                1      0              113803   53.1000  C123        S   \n",
       "5                0      0              373450    8.0500   NaN        S   \n",
       "...            ...    ...                 ...       ...   ...      ...   \n",
       "1305             0      0           A.5. 3236    8.0500   NaN        S   \n",
       "1306             0      0            PC 17758  108.9000  C105        C   \n",
       "1307             0      0  SOTON/O.Q. 3101262    7.2500   NaN        S   \n",
       "1308             0      0              359309    8.0500   NaN        S   \n",
       "1309             1      1                2668   22.3583   NaN        C   \n",
       "\n",
       "             WikiId                                   Name_wiki  Age_wiki  \\\n",
       "PassengerId                                                                 \n",
       "1             691.0                     Braund, Mr. Owen Harris      22.0   \n",
       "2              90.0  Cumings, Mrs. Florence Briggs (née Thayer)      35.0   \n",
       "3             865.0                       Heikkinen, Miss Laina      26.0   \n",
       "4             127.0          Futrelle, Mrs. Lily May (née Peel)      35.0   \n",
       "5             627.0                    Allen, Mr. William Henry      35.0   \n",
       "...             ...                                         ...       ...   \n",
       "1305         1227.0                          Spector, Mr. Woolf      23.0   \n",
       "1306          229.0        and maid, Doña Fermina Oliva y Ocana      39.0   \n",
       "1307         1169.0                 Sæther, Mr. Simon Sivertsen      43.0   \n",
       "1308         1289.0                 Ware, Mr. Frederick William      34.0   \n",
       "1309          702.0             Butrus-Youssef, Master Makhkhul       4.0   \n",
       "\n",
       "                                       Hometown      Boarded  \\\n",
       "PassengerId                                                    \n",
       "1                    Bridgerule, Devon, England  Southampton   \n",
       "2                        New York, New York, US    Cherbourg   \n",
       "3                            Jyväskylä, Finland  Southampton   \n",
       "4                   Scituate, Massachusetts, US  Southampton   \n",
       "5            Birmingham, West Midlands, England  Southampton   \n",
       "...                                         ...          ...   \n",
       "1305                            London, England  Southampton   \n",
       "1306                              Madrid, Spain    Cherbourg   \n",
       "1307               Skaun, Sør-Trøndelag, Norway  Southampton   \n",
       "1308                 Greenwich, London, England  Southampton   \n",
       "1309                          Sar'al[81], Syria    Cherbourg   \n",
       "\n",
       "                                         Destination Lifeboat  Body  \n",
       "PassengerId                                                          \n",
       "1            Qu'Appelle Valley, Saskatchewan, Canada      NaN   NaN  \n",
       "2                             New York, New York, US        4   NaN  \n",
       "3                                      New York City      14?   NaN  \n",
       "4                        Scituate, Massachusetts, US        D   NaN  \n",
       "5                                      New York City      NaN   NaN  \n",
       "...                                              ...      ...   ...  \n",
       "1305                                   New York City      NaN   NaN  \n",
       "1306                          New York, New York, US        8   NaN  \n",
       "1307                                              US      NaN  32MB  \n",
       "1308                                   New York City      NaN   NaN  \n",
       "1309                           Detroit, Michigan, US        D   NaN  \n",
       "\n",
       "[1309 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Class', axis = 'columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a0c5f",
   "metadata": {},
   "source": [
    "### Converting DataFrame Column Names to Lowercase snakecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c34f2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sib_sp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>name_wiki</th>\n",
       "      <th>age_wiki</th>\n",
       "      <th>hometown</th>\n",
       "      <th>boarded</th>\n",
       "      <th>destination</th>\n",
       "      <th>lifeboat</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>691.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Bridgerule, Devon, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Qu'Appelle Valley, Saskatchewan, Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Cumings, Mrs. Florence Briggs (née Thayer)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>865.0</td>\n",
       "      <td>Heikkinen, Miss Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Jyväskylä, Finland</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>14?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Futrelle, Mrs. Lily May (née Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>627.0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Birmingham, West Midlands, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>23.0</td>\n",
       "      <td>London, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>229.0</td>\n",
       "      <td>and maid, Doña Fermina Oliva y Ocana</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Madrid, Spain</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>Sæther, Mr. Simon Sivertsen</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Skaun, Sør-Trøndelag, Norway</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>Ware, Mr. Frederick William</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Greenwich, London, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>702.0</td>\n",
       "      <td>Butrus-Youssef, Master Makhkhul</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sar'al[81], Syria</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Detroit, Michigan, US</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             survived  pclass  \\\n",
       "PassengerId                     \n",
       "1                 0.0       3   \n",
       "2                 1.0       1   \n",
       "3                 1.0       3   \n",
       "4                 1.0       1   \n",
       "5                 0.0       3   \n",
       "...               ...     ...   \n",
       "1305              NaN       3   \n",
       "1306              NaN       1   \n",
       "1307              NaN       3   \n",
       "1308              NaN       3   \n",
       "1309              NaN       3   \n",
       "\n",
       "                                                          name     sex   age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "1305                                        Spector, Mr. Woolf    male   NaN   \n",
       "1306                              Oliva y Ocana, Dona. Fermina  female  39.0   \n",
       "1307                              Saether, Mr. Simon Sivertsen    male  38.5   \n",
       "1308                                       Ware, Mr. Frederick    male   NaN   \n",
       "1309                                  Peter, Master. Michael J    male   NaN   \n",
       "\n",
       "             sib_sp  parch              ticket      fare cabin embarked  \\\n",
       "PassengerId                                                               \n",
       "1                 1      0           A/5 21171    7.2500   NaN        S   \n",
       "2                 1      0            PC 17599   71.2833   C85        C   \n",
       "3                 0      0    STON/O2. 3101282    7.9250   NaN        S   \n",
       "4                 1      0              113803   53.1000  C123        S   \n",
       "5                 0      0              373450    8.0500   NaN        S   \n",
       "...             ...    ...                 ...       ...   ...      ...   \n",
       "1305              0      0           A.5. 3236    8.0500   NaN        S   \n",
       "1306              0      0            PC 17758  108.9000  C105        C   \n",
       "1307              0      0  SOTON/O.Q. 3101262    7.2500   NaN        S   \n",
       "1308              0      0              359309    8.0500   NaN        S   \n",
       "1309              1      1                2668   22.3583   NaN        C   \n",
       "\n",
       "             wiki_id                                   name_wiki  age_wiki  \\\n",
       "PassengerId                                                                  \n",
       "1              691.0                     Braund, Mr. Owen Harris      22.0   \n",
       "2               90.0  Cumings, Mrs. Florence Briggs (née Thayer)      35.0   \n",
       "3              865.0                       Heikkinen, Miss Laina      26.0   \n",
       "4              127.0          Futrelle, Mrs. Lily May (née Peel)      35.0   \n",
       "5              627.0                    Allen, Mr. William Henry      35.0   \n",
       "...              ...                                         ...       ...   \n",
       "1305          1227.0                          Spector, Mr. Woolf      23.0   \n",
       "1306           229.0        and maid, Doña Fermina Oliva y Ocana      39.0   \n",
       "1307          1169.0                 Sæther, Mr. Simon Sivertsen      43.0   \n",
       "1308          1289.0                 Ware, Mr. Frederick William      34.0   \n",
       "1309           702.0             Butrus-Youssef, Master Makhkhul       4.0   \n",
       "\n",
       "                                       hometown      boarded  \\\n",
       "PassengerId                                                    \n",
       "1                    Bridgerule, Devon, England  Southampton   \n",
       "2                        New York, New York, US    Cherbourg   \n",
       "3                            Jyväskylä, Finland  Southampton   \n",
       "4                   Scituate, Massachusetts, US  Southampton   \n",
       "5            Birmingham, West Midlands, England  Southampton   \n",
       "...                                         ...          ...   \n",
       "1305                            London, England  Southampton   \n",
       "1306                              Madrid, Spain    Cherbourg   \n",
       "1307               Skaun, Sør-Trøndelag, Norway  Southampton   \n",
       "1308                 Greenwich, London, England  Southampton   \n",
       "1309                          Sar'al[81], Syria    Cherbourg   \n",
       "\n",
       "                                         destination lifeboat  body  \n",
       "PassengerId                                                          \n",
       "1            Qu'Appelle Valley, Saskatchewan, Canada      NaN   NaN  \n",
       "2                             New York, New York, US        4   NaN  \n",
       "3                                      New York City      14?   NaN  \n",
       "4                        Scituate, Massachusetts, US        D   NaN  \n",
       "5                                      New York City      NaN   NaN  \n",
       "...                                              ...      ...   ...  \n",
       "1305                                   New York City      NaN   NaN  \n",
       "1306                          New York, New York, US        8   NaN  \n",
       "1307                                              US      NaN  32MB  \n",
       "1308                                   New York City      NaN   NaN  \n",
       "1309                           Detroit, Michigan, US        D   NaN  \n",
       "\n",
       "[1309 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = (df.columns\n",
    "                .str.replace('(?<=[a-z])(?=[A-Z])', '_', regex=True)\n",
    "                .str.lower()\n",
    "             )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a274ef",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c575a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns taht do not add value\n",
    "df = df.drop(columns = ['name',\n",
    "                        'name_wiki',\n",
    "                        'wiki_id',\n",
    "                        'hometown',\n",
    "                        'destination',\n",
    "                        'ticket',\n",
    "                        'lifeboat',\n",
    "                        'body',\n",
    "                        'cabin',\n",
    "                        'age'])\n",
    "\n",
    "# using get_dummies function to convert object to float\n",
    "df = pd.get_dummies(df, dtype = float)\n",
    "\n",
    "# dropping redundant features\n",
    "df = df.drop(columns = ['sex_male'])\n",
    "\n",
    "#remove rows with any values that are not finite (NaN or infite)\n",
    "df = df[np.isfinite(df).all(1)]\n",
    "\n",
    "# first, we need to create a series of the target feature\n",
    "y = df.survived\n",
    "\n",
    "# then, we create a DataFrame with the attributes\n",
    "X = df.drop(columns = ['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af977d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sib_sp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>age_wiki</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>boarded_Belfast</th>\n",
       "      <th>boarded_Cherbourg</th>\n",
       "      <th>boarded_Queenstown</th>\n",
       "      <th>boarded_Southampton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             survived  pclass  sib_sp  parch     fare  age_wiki  sex_female  \\\n",
       "PassengerId                                                                   \n",
       "1                 0.0       3       1      0   7.2500      22.0         0.0   \n",
       "2                 1.0       1       1      0  71.2833      35.0         1.0   \n",
       "3                 1.0       3       0      0   7.9250      26.0         1.0   \n",
       "4                 1.0       1       1      0  53.1000      35.0         1.0   \n",
       "5                 0.0       3       0      0   8.0500      35.0         0.0   \n",
       "...               ...     ...     ...    ...      ...       ...         ...   \n",
       "887               0.0       2       0      0  13.0000      27.0         0.0   \n",
       "888               1.0       1       0      0  30.0000      19.0         1.0   \n",
       "889               0.0       3       1      2  23.4500       7.0         1.0   \n",
       "890               1.0       1       0      0  30.0000      26.0         0.0   \n",
       "891               0.0       3       0      0   7.7500      43.0         0.0   \n",
       "\n",
       "             embarked_C  embarked_Q  embarked_S  boarded_Belfast  \\\n",
       "PassengerId                                                        \n",
       "1                   0.0         0.0         1.0              0.0   \n",
       "2                   1.0         0.0         0.0              0.0   \n",
       "3                   0.0         0.0         1.0              0.0   \n",
       "4                   0.0         0.0         1.0              0.0   \n",
       "5                   0.0         0.0         1.0              0.0   \n",
       "...                 ...         ...         ...              ...   \n",
       "887                 0.0         0.0         1.0              0.0   \n",
       "888                 0.0         0.0         1.0              0.0   \n",
       "889                 0.0         0.0         1.0              0.0   \n",
       "890                 1.0         0.0         0.0              0.0   \n",
       "891                 0.0         1.0         0.0              0.0   \n",
       "\n",
       "             boarded_Cherbourg  boarded_Queenstown  boarded_Southampton  \n",
       "PassengerId                                                              \n",
       "1                          0.0                 0.0                  1.0  \n",
       "2                          1.0                 0.0                  0.0  \n",
       "3                          0.0                 0.0                  1.0  \n",
       "4                          0.0                 0.0                  1.0  \n",
       "5                          0.0                 0.0                  1.0  \n",
       "...                        ...                 ...                  ...  \n",
       "887                        0.0                 0.0                  1.0  \n",
       "888                        0.0                 0.0                  1.0  \n",
       "889                        0.0                 0.0                  1.0  \n",
       "890                        1.0                 0.0                  0.0  \n",
       "891                        0.0                 1.0                  0.0  \n",
       "\n",
       "[887 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9507c5a",
   "metadata": {},
   "source": [
    "### Standardizing the Data\n",
    "Some Machine Learning algorithms perform better when the data is standardized, that is, each feature must have mean = 0 and standard deviation = 1<br>\n",
    "In this case, we will use the StandardScaler from sklearn lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06313f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.79027978,  0.82864696,  0.43091521, ..., -0.47626951,\n",
       "        -0.30612329,  0.62472565],\n",
       "       [ 1.26537466, -1.56552195,  0.43091521, ...,  2.09965154,\n",
       "        -0.30612329, -1.60070266],\n",
       "       [ 1.26537466,  0.82864696, -0.47482363, ..., -0.47626951,\n",
       "        -0.30612329,  0.62472565],\n",
       "       ...,\n",
       "       [-0.79027978,  0.82864696,  0.43091521, ..., -0.47626951,\n",
       "        -0.30612329,  0.62472565],\n",
       "       [ 1.26537466, -1.56552195, -0.47482363, ...,  2.09965154,\n",
       "        -0.30612329, -1.60070266],\n",
       "       [-0.79027978,  0.82864696, -0.47482363, ..., -0.47626951,\n",
       "         3.26665772, -1.60070266]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copying the dataset\n",
    "df_std = df.copy()\n",
    "\n",
    "# assigning StandardScaler to a variable\n",
    "std = preprocessing.StandardScaler()\n",
    "\n",
    "# applying the standard scaler\n",
    "std.fit_transform(df_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff8f546",
   "metadata": {},
   "source": [
    "#### Some attributes of StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd7d057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.84441939e-01, 2.30777903e+00, 5.24239008e-01, 3.83314543e-01,\n",
       "       3.20569703e+01, 2.93220631e+01, 3.52874859e-01, 1.86020293e-01,\n",
       "       8.68094701e-02, 7.24915445e-01, 1.01465614e-02, 1.84892897e-01,\n",
       "       8.56820744e-02, 7.19278467e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean\n",
    "std.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6352546e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.36646335e-01, 6.97831257e-01, 1.21897279e+00, 6.51266128e-01,\n",
       "       2.43313214e+03, 1.93828605e+02, 2.28354193e-01, 1.51416744e-01,\n",
       "       7.92735860e-02, 1.99413042e-01, 1.00436087e-02, 1.50707514e-01,\n",
       "       7.83406565e-02, 2.01916954e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance\n",
    "std.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b394b6",
   "metadata": {},
   "source": [
    "### Min-Max-Scaler\n",
    "Min-Max Scaling, also known as scaling normalization, is another widely used Feature Scaling technique. In this approach, feature values are set to a specific range, usually between 0 and 1.<br>\n",
    "We are not going to use MinMaxScaler on the dataset, but we will leave the code for future possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d473ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  return lib.map_infer(values, mapper, convert=convert)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 1.   , 0.125, ..., 0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.125, ..., 1.   , 0.   , 0.   ],\n",
       "       [1.   , 1.   , 0.   , ..., 0.   , 0.   , 1.   ],\n",
       "       ...,\n",
       "       [0.   , 1.   , 0.125, ..., 0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   , ..., 1.   , 0.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   , ..., 0.   , 1.   , 0.   ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copying the dataset\n",
    "df_mms = df.copy()\n",
    "\n",
    "# assigning MinMaxScaler to a variable\n",
    "mms = preprocessing.MinMaxScaler()\n",
    "\n",
    "# applying the minimum and maximum scaler\n",
    "mms.fit_transform(df_mms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e0f19",
   "metadata": {},
   "source": [
    "### Dummies features\n",
    "Dummy variables are binary variables (0 or 1) created to represent a variable with two or more categories.<br>\n",
    "Dummy variables must be used whenever we wish to include categorical variables in models that only accept numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "389d27fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sib_sp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>age_wiki</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>boarded_Belfast</th>\n",
       "      <th>boarded_Cherbourg</th>\n",
       "      <th>boarded_Queenstown</th>\n",
       "      <th>boarded_Southampton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             survived  pclass  sib_sp  parch     fare  age_wiki  sex_female  \\\n",
       "PassengerId                                                                   \n",
       "1                 0.0       3       1      0   7.2500      22.0         0.0   \n",
       "2                 1.0       1       1      0  71.2833      35.0         1.0   \n",
       "3                 1.0       3       0      0   7.9250      26.0         1.0   \n",
       "4                 1.0       1       1      0  53.1000      35.0         1.0   \n",
       "5                 0.0       3       0      0   8.0500      35.0         0.0   \n",
       "...               ...     ...     ...    ...      ...       ...         ...   \n",
       "887               0.0       2       0      0  13.0000      27.0         0.0   \n",
       "888               1.0       1       0      0  30.0000      19.0         1.0   \n",
       "889               0.0       3       1      2  23.4500       7.0         1.0   \n",
       "890               1.0       1       0      0  30.0000      26.0         0.0   \n",
       "891               0.0       3       0      0   7.7500      43.0         0.0   \n",
       "\n",
       "             embarked_C  embarked_Q  embarked_S  boarded_Belfast  \\\n",
       "PassengerId                                                        \n",
       "1                   0.0         0.0         1.0              0.0   \n",
       "2                   1.0         0.0         0.0              0.0   \n",
       "3                   0.0         0.0         1.0              0.0   \n",
       "4                   0.0         0.0         1.0              0.0   \n",
       "5                   0.0         0.0         1.0              0.0   \n",
       "...                 ...         ...         ...              ...   \n",
       "887                 0.0         0.0         1.0              0.0   \n",
       "888                 0.0         0.0         1.0              0.0   \n",
       "889                 0.0         0.0         1.0              0.0   \n",
       "890                 1.0         0.0         0.0              0.0   \n",
       "891                 0.0         1.0         0.0              0.0   \n",
       "\n",
       "             boarded_Cherbourg  boarded_Queenstown  boarded_Southampton  \n",
       "PassengerId                                                              \n",
       "1                          0.0                 0.0                  1.0  \n",
       "2                          1.0                 0.0                  0.0  \n",
       "3                          0.0                 0.0                  1.0  \n",
       "4                          0.0                 0.0                  1.0  \n",
       "5                          0.0                 0.0                  1.0  \n",
       "...                        ...                 ...                  ...  \n",
       "887                        0.0                 0.0                  1.0  \n",
       "888                        0.0                 0.0                  1.0  \n",
       "889                        0.0                 0.0                  1.0  \n",
       "890                        1.0                 0.0                  0.0  \n",
       "891                        0.0                 1.0                  0.0  \n",
       "\n",
       "[887 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using get_dummies function to convert object to boolean\n",
    "df = pd.get_dummies(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05229d8",
   "metadata": {},
   "source": [
    "Note that variables that were previously _object_ are now of type _boolean_.\n",
    "We can convert the features to float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d6f2501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sib_sp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>age_wiki</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>boarded_Belfast</th>\n",
       "      <th>boarded_Cherbourg</th>\n",
       "      <th>boarded_Queenstown</th>\n",
       "      <th>boarded_Southampton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             survived  pclass  sib_sp  parch     fare  age_wiki  sex_female  \\\n",
       "PassengerId                                                                   \n",
       "1                 0.0       3       1      0   7.2500      22.0         0.0   \n",
       "2                 1.0       1       1      0  71.2833      35.0         1.0   \n",
       "3                 1.0       3       0      0   7.9250      26.0         1.0   \n",
       "4                 1.0       1       1      0  53.1000      35.0         1.0   \n",
       "5                 0.0       3       0      0   8.0500      35.0         0.0   \n",
       "...               ...     ...     ...    ...      ...       ...         ...   \n",
       "887               0.0       2       0      0  13.0000      27.0         0.0   \n",
       "888               1.0       1       0      0  30.0000      19.0         1.0   \n",
       "889               0.0       3       1      2  23.4500       7.0         1.0   \n",
       "890               1.0       1       0      0  30.0000      26.0         0.0   \n",
       "891               0.0       3       0      0   7.7500      43.0         0.0   \n",
       "\n",
       "             embarked_C  embarked_Q  embarked_S  boarded_Belfast  \\\n",
       "PassengerId                                                        \n",
       "1                   0.0         0.0         1.0              0.0   \n",
       "2                   1.0         0.0         0.0              0.0   \n",
       "3                   0.0         0.0         1.0              0.0   \n",
       "4                   0.0         0.0         1.0              0.0   \n",
       "5                   0.0         0.0         1.0              0.0   \n",
       "...                 ...         ...         ...              ...   \n",
       "887                 0.0         0.0         1.0              0.0   \n",
       "888                 0.0         0.0         1.0              0.0   \n",
       "889                 0.0         0.0         1.0              0.0   \n",
       "890                 1.0         0.0         0.0              0.0   \n",
       "891                 0.0         1.0         0.0              0.0   \n",
       "\n",
       "             boarded_Cherbourg  boarded_Queenstown  boarded_Southampton  \n",
       "PassengerId                                                              \n",
       "1                          0.0                 0.0                  1.0  \n",
       "2                          1.0                 0.0                  0.0  \n",
       "3                          0.0                 0.0                  1.0  \n",
       "4                          0.0                 0.0                  1.0  \n",
       "5                          0.0                 0.0                  1.0  \n",
       "...                        ...                 ...                  ...  \n",
       "887                        0.0                 0.0                  1.0  \n",
       "888                        0.0                 0.0                  1.0  \n",
       "889                        0.0                 0.0                  1.0  \n",
       "890                        1.0                 0.0                  0.0  \n",
       "891                        0.0                 1.0                  0.0  \n",
       "\n",
       "[887 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using get_dummies function to convert object to float\n",
    "df = pd.get_dummies(df, dtype=float)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662cc778",
   "metadata": {},
   "source": [
    "### Label Encoder\n",
    "An alternative to dummy variable coding is label coding. In this case, each category data will be assigned a number. It is a convenient method for data with high cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a1639b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1,\n",
       "       2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 2, 2, 1, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 1, 0, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 2, 1,\n",
       "       2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 1, 2, 2, 2, 0,\n",
       "       2, 2, 2, 0, 2, 2, 2, 0, 0, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 2, 2, 1, 0, 2, 1, 2, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 2, 2,\n",
       "       0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2,\n",
       "       0, 1, 2, 2, 1, 2, 1, 2, 0, 2, 0, 2, 2, 1, 1, 2, 1, 0, 0, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 1, 2, 0, 2, 1, 0, 1, 2,\n",
       "       1, 2, 2, 0, 2, 1, 2, 1, 2, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1,\n",
       "       2, 2, 0, 2, 1, 0, 1, 2, 2, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 0, 0, 2,\n",
       "       1, 2, 2, 0, 0, 0, 2, 1, 0, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 1, 2, 0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 2, 1, 2, 1, 1, 0, 0, 2, 2, 1, 1, 2, 0, 2, 1, 2, 0, 2,\n",
       "       0, 0, 2, 0, 2, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 0,\n",
       "       2, 0, 2, 2, 0, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 2, 0, 2, 2, 2, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 0, 1, 2, 2, 1, 1, 1, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 2, 0, 2, 1, 2, 0, 0, 2, 1, 0, 1, 1, 2, 2,\n",
       "       1, 2, 0, 1, 0, 2, 0, 1, 2, 0, 0, 2, 2, 0, 0, 1, 2, 0, 2, 0, 1, 2,\n",
       "       2, 1, 0, 2, 2, 2, 2, 1, 1, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0,\n",
       "       0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 1, 0, 2,\n",
       "       2, 2, 2, 0, 0, 2, 0, 1, 2, 1, 2, 0, 2, 2, 0, 2, 2, 1, 0, 2, 1, 1,\n",
       "       2, 2, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 1, 2,\n",
       "       2, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 2, 2, 2,\n",
       "       1, 0, 2, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 2, 2, 0, 2, 2, 1, 2, 1, 2,\n",
       "       2, 0, 1, 2, 0, 2, 0, 2, 2, 0, 1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1,\n",
       "       2, 0, 2, 2, 2, 0, 1, 0, 2, 2, 0, 2, 0, 0, 2, 1, 2, 1, 2, 2, 2, 0,\n",
       "       2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2,\n",
       "       2, 1, 1, 2, 2, 0, 1, 0, 1, 1, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 1, 1,\n",
       "       2, 2, 2, 0, 0, 2, 2, 2, 0, 1, 2, 2, 0, 2, 0, 0, 2, 2, 2, 1, 1, 0,\n",
       "       0, 2, 0, 0, 0, 2, 1, 2, 0, 1, 2, 2, 1, 2, 1, 1, 0, 2, 1, 2, 1, 2,\n",
       "       0, 2, 1, 1, 1, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 1, 0, 2, 1, 2,\n",
       "       2, 2, 1, 1, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 1, 2,\n",
       "       1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 0, 2, 1,\n",
       "       0, 2, 2, 2, 1, 1, 0, 2, 2, 2, 0, 2, 1, 0, 2, 2, 1, 2, 2, 0, 2, 1,\n",
       "       2, 2, 0, 2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 0, 2, 2, 2, 0,\n",
       "       2, 1, 0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 0, 1, 2, 0, 0, 2, 2, 2, 1,\n",
       "       0, 2, 1, 1, 1, 0, 2, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 0, 1, 2, 2, 1,\n",
       "       2, 2, 1, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copying the dataset\n",
    "df_lbe = df['pclass'].copy()\n",
    "\n",
    "# assigning LabelEncoder to a variable\n",
    "labenc = preprocessing.LabelEncoder()\n",
    "\n",
    "# applying the label encoder\n",
    "labenc.fit_transform(df_lbe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129ecdd",
   "metadata": {},
   "source": [
    "We can decode the LabelEncoder from the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "258a23e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the inverse codification\n",
    "labenc.inverse_transform([2, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac849b3f",
   "metadata": {},
   "source": [
    "### Extracting Categories from Strings\n",
    "One of the ways to increase the accuracy of models is to extract the titles of names.<br>\n",
    "We can use the Counter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a20e123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(', M', 1282),\n",
       " (' Mr', 954),\n",
       " ('r. ', 830),\n",
       " ('Mr.', 757),\n",
       " ('s. ', 460),\n",
       " ('n, ', 320),\n",
       " (' Mi', 285),\n",
       " ('iss', 261),\n",
       " ('ss.', 261),\n",
       " ('Mis', 260)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "\n",
    "def triples(val):\n",
    "    for i in range(len(val)):\n",
    "        c[val[i : i + 3]] += 1\n",
    "\n",
    "df = pd.read_csv(\"titanic_dataset.csv\", index_col=0)\n",
    "\n",
    "df.columns = (df.columns\n",
    "                .str.replace('(?<=[a-z])(?=[A-Z])', '_', regex=True)\n",
    "                .str.lower()\n",
    "             )\n",
    "\n",
    "df.name.apply(triples)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd512c",
   "metadata": {},
   "source": [
    "### Other Encodings\n",
    "The _categorical_encoding_ lib is a set of scikit-learn transformers used to convert object data to numeric data.<br>\n",
    "A good feature of this lib is that it generates pandas DataFrames.<br>\n",
    "One of the algorithms implemented in this lib is a hash encoder.\n",
    "Another ordinal algorithm (_ordinal encoder_) can convert category columns that have an order into a single column of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e217e1",
   "metadata": {},
   "source": [
    "### Data Engineering\n",
    "We can use pandas to generate new attributes. Sometimes, we can receive these transformations from the Engineering team, but other times, we need to create these visions ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f43f1d9",
   "metadata": {},
   "source": [
    "#### Aggregate\n",
    "We can aggregate cabin data, class, ticket price, among others, with age (average, mode, maximum, minimum, ...). For this, we will use .groupby() method from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb69698d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived    float64\n",
       "pclass        int64\n",
       "age         float64\n",
       "sib_sp        int64\n",
       "parch         int64\n",
       "fare        float64\n",
       "cabin        object\n",
       "wiki_id     float64\n",
       "age_wiki    float64\n",
       "class       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = ['name',\n",
    "'sex',\n",
    "'ticket',\n",
    "'embarked',\n",
    "'name_wiki',\n",
    "'hometown',\n",
    "'boarded',\n",
    "'destination',\n",
    "'lifeboat',\n",
    "'body'])\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5eab80b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sib_sp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>age_wiki</th>\n",
       "      <th>class</th>\n",
       "      <th>...</th>\n",
       "      <th>wiki_id_mean</th>\n",
       "      <th>wiki_id_sum</th>\n",
       "      <th>age_wiki_min</th>\n",
       "      <th>age_wiki_max</th>\n",
       "      <th>age_wiki_mean</th>\n",
       "      <th>age_wiki_sum</th>\n",
       "      <th>class_min</th>\n",
       "      <th>class_max</th>\n",
       "      <th>class_mean</th>\n",
       "      <th>class_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>90.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.5</td>\n",
       "      <td>179.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>127.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.5</td>\n",
       "      <td>253.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>200.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>179.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1211.2</td>\n",
       "      <td>6056.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>35.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>D40</td>\n",
       "      <td>122.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>D38</td>\n",
       "      <td>218.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>218.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>C80</td>\n",
       "      <td>316.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>317.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>C78</td>\n",
       "      <td>206.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>206.5</td>\n",
       "      <td>826.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>229.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sib_sp  parch      fare cabin  wiki_id  age_wiki  \\\n",
       "0         1.0       1  38.0       1      0   71.2833   C85     90.0      35.0   \n",
       "1         1.0       1  35.0       1      0   53.1000  C123    127.0      35.0   \n",
       "2         0.0       1  54.0       0      0   51.8625   E46    200.0      54.0   \n",
       "3         1.0       3   4.0       1      1   16.7000    G6   1193.0       4.0   \n",
       "4         1.0       1  58.0       0      0   26.5500  C103     35.0      61.0   \n",
       "..        ...     ...   ...     ...    ...       ...   ...      ...       ...   \n",
       "290       NaN       1  43.0       1      0   27.7208   D40    122.0      43.0   \n",
       "291       NaN       2  20.0       0      0   13.8625   D38    218.0      20.0   \n",
       "292       NaN       1  50.0       1      1  211.5000   C80    316.0      50.0   \n",
       "293       NaN       1  37.0       1      0   90.0000   C78    206.0      37.0   \n",
       "294       NaN       1  39.0       0      0  108.9000  C105    229.0      39.0   \n",
       "\n",
       "     class  ...  wiki_id_mean  wiki_id_sum  age_wiki_min  age_wiki_max  \\\n",
       "0      1.0  ...          89.5        179.0          35.0          39.0   \n",
       "1      1.0  ...         126.5        253.0          35.0          37.0   \n",
       "2      1.0  ...         179.0        358.0          44.0          54.0   \n",
       "3      3.0  ...        1211.2       6056.0           1.0          29.0   \n",
       "4      1.0  ...          35.0         35.0          61.0          61.0   \n",
       "..     ...  ...           ...          ...           ...           ...   \n",
       "290    1.0  ...         122.0        122.0          43.0          43.0   \n",
       "291    1.0  ...         218.0        218.0          20.0          20.0   \n",
       "292    1.0  ...         317.0        634.0          50.0          50.0   \n",
       "293    1.0  ...         206.5        826.0          30.0          44.0   \n",
       "294    1.0  ...         229.0        229.0          39.0          39.0   \n",
       "\n",
       "     age_wiki_mean  age_wiki_sum  class_min  class_max  class_mean  class_sum  \n",
       "0             37.0          74.0        1.0        1.0         1.0        2.0  \n",
       "1             36.0          72.0        1.0        1.0         1.0        2.0  \n",
       "2             49.0          98.0        1.0        1.0         1.0        2.0  \n",
       "3             12.0          60.0        3.0        3.0         3.0       15.0  \n",
       "4             61.0          61.0        1.0        1.0         1.0        1.0  \n",
       "..             ...           ...        ...        ...         ...        ...  \n",
       "290           43.0          43.0        1.0        1.0         1.0        1.0  \n",
       "291           20.0          20.0        1.0        1.0         1.0        1.0  \n",
       "292           50.0         100.0        1.0        1.0         1.0        2.0  \n",
       "293           36.0         144.0        1.0        1.0         1.0        4.0  \n",
       "294           39.0          39.0        1.0        1.0         1.0        1.0  \n",
       "\n",
       "[295 rows x 46 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = (\n",
    "    df.groupby(\"cabin\")\n",
    "    .agg(\"min,max,mean,sum\".split(\",\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "agg.columns = [\n",
    "    \"_\".join(c).strip(\"_\")\n",
    "    for c in agg.columns.values\n",
    "]\n",
    "\n",
    "agg_df = df.merge(agg, on = \"cabin\")\n",
    "\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436b9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
