{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0caa1a0f",
   "metadata": {},
   "source": [
    "### Intalling libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74e34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239cc03",
   "metadata": {},
   "source": [
    "### Column description\n",
    "\n",
    "| Variável \t| Descrição \t|\n",
    "|:-:\t|:-\t|\n",
    "|CRIM   | Taxa de crimes per capita por cidade \t|\n",
    "|ZN     | Proporção de áreas residenciais zoneadas para lotes acima de 25 mil pés quadrados (aproximadamente 2.320 metros quadrados|\n",
    "|INDUS  | Proporção de acres para negócios não ligados ao varejo por cidade|\n",
    "|CHAS   | Variável dummy sobre Rio Charles (1 se a região faz fronteira com rio; 0 caso contrário)|\n",
    "|NOX    | Concentração de óxidos nítricos (partes por 0 milhões)|\n",
    "|RM     | Número médio de cômodos por habitação|\n",
    "|AGE    | Proporção de unidades ocupadas por proprietários construídas antes de 1940|\n",
    "|DIS    | Distâncias ponderadas até cinco centros de empregos em Boston|\n",
    "|RAD    | Índice de acessibilidade às rodovias radiais|\n",
    "|TAX    | Taxa de impostos sobre o valor total da propriedade por 10 mil dólares|\n",
    "|PTRATIO| Razão entre aluno-professor por cidade|\n",
    "|B      | 1000(Bk - 0.63) ^ 2 em que Bk é a proporção de negros (Bk = Black) por cidade (conjunto de dados de 1978)|\n",
    "|LSTAT  | Porcentagem da população com status mais baixo|\n",
    "|MEDV   | Valor médio das casas ocupadas por proprietários em incrementos de 1000 dólares|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696865d3",
   "metadata": {},
   "source": [
    "### Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c7b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset import\n",
    "from sklearn.datasets import (\n",
    "    load_boston\n",
    ")\n",
    "\n",
    "# data visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from seaborn import (\n",
    "    jointplot,\n",
    "    pairplot,\n",
    "    boxplot,\n",
    "    heatmap\n",
    ")\n",
    "\n",
    "from yellowbrick.features import (\n",
    "    Rank2D, \n",
    "    RadViz,\n",
    "    FeatureImportances,\n",
    "    ParallelCoordinates,\n",
    "    JointPlotVisualizer,\n",
    ")\n",
    "\n",
    "from yellowbrick.classifier import (\n",
    "    ConfusionMatrix\n",
    ")\n",
    "\n",
    "import dtreeviz\n",
    "\n",
    "import pydotplus\n",
    "\n",
    "from io import(\n",
    "    StringIO\n",
    ")\n",
    "\n",
    "from IPython.display import (\n",
    "    Image\n",
    ")\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import(\n",
    "    radviz\n",
    ")\n",
    "\n",
    "import janitor as jn\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# missing values\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.impute import (\n",
    "    SimpleImputer\n",
    ")\n",
    "\n",
    "# machine learning models\n",
    "from sklearn import (\n",
    "    svm,\n",
    "    tree,\n",
    "    impute,\n",
    "    ensemble,\n",
    "    preprocessing,\n",
    "    model_selection\n",
    ")\n",
    "\n",
    "from sklearn.utils import (\n",
    "    resample\n",
    ")\n",
    "\n",
    "from sklearn.dummy import (\n",
    "    DummyClassifier\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split\n",
    ")\n",
    "\n",
    "from sklearn.experimental import (\n",
    "    enable_iterative_imputer\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression\n",
    ")\n",
    "\n",
    "from sklearn.naive_bayes import (\n",
    "    GaussianNB\n",
    ")\n",
    "\n",
    "from sklearn.tree import (\n",
    "    DecisionTreeClassifier,\n",
    "    export_graphviz,\n",
    "    plot_tree\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import (\n",
    "    KNeighborsClassifier\n",
    ")\n",
    "\n",
    "from sklearn.naive_bayes import (\n",
    "    GaussianNB\n",
    ")\n",
    "\n",
    "from sklearn.svm import (\n",
    "    SVC\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import (\n",
    "    RandomOverSampler,\n",
    ")\n",
    "\n",
    "from sklearn.dummy import (\n",
    "    DummyRegressor\n",
    ")\n",
    "\n",
    "import shap\n",
    "\n",
    "import rfpimp\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import xgbfir\n",
    "\n",
    "# data model metrics\n",
    "from lime import (\n",
    "    lime_tabular\n",
    ")\n",
    "\n",
    "from treeinterpreter import (\n",
    "    treeinterpreter as ti\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "import scikitplot as skplt\n",
    "\n",
    "from yellowbrick.classifier import (\n",
    "    ROCAUC,\n",
    "    ClassBalance,\n",
    "    ConfusionMatrix,\n",
    "    ClassPredictionError,\n",
    "    ClassificationReport,\n",
    "    PrecisionRecallCurve,\n",
    "    DiscriminationThreshold,\n",
    ")\n",
    "\n",
    "from yellowbrick.model_selection import (\n",
    "    LearningCurve,\n",
    "    ValidationCurve,\n",
    ")\n",
    "\n",
    "# data prep-model\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    learning_curve\n",
    ")\n",
    "\n",
    "# model deploy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee90199",
   "metadata": {},
   "source": [
    "### Regression\n",
    "**Regression** is a supervised machine learning process. It is similar to classification, but instead of predicting a label (target), it tries to predict a continuous (numeric) value.<br><br>\n",
    "The fact is that **sklearn** is capable of applying many of the same **classification** models to **regression** problems. In effect, the API is the same and calls *.fit*, *.score*, and *.predict*.<br><br>\n",
    "For the **regression**, we will use a Boston housing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e460a7d",
   "metadata": {},
   "source": [
    "### Reading the Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fd67e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# loading boston dataset\n",
    "b = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a274ef",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045dc6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating X dataset\n",
    "bos_X = pd.DataFrame(b.data, columns=b.feature_names)\n",
    "\n",
    "# creating y dataset\n",
    "bos_y = b.target\n",
    "\n",
    "# train_test_split dataset\n",
    "bos_X_train, bos_X_test, bos_y_train, bos_y_test = model_selection.train_test_split(\n",
    "    bos_X,\n",
    "    bos_y,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bos_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34706175",
   "metadata": {},
   "source": [
    "### Preparing the standardized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92d4c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "/Users/dellacorte/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "bos_sX = preprocessing.StandardScaler().fit_transform(\n",
    "    bos_X\n",
    ")\n",
    "\n",
    "bos_sX_train, bos_sX_test, bos_sy_train, bos_sy_test = model_selection.train_test_split(\n",
    "    bos_sX,\n",
    "    bos_y, test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318e8da",
   "metadata": {},
   "source": [
    "### Base model\n",
    "A basic regression model can give us something against which we can compare other models.<br><br>\n",
    "No **skear**, the default result of the *.score()* method is the *coefficient of determination* (*r2 or R2*). This number explains the percentage of variation in the input data captured by the forecast. In general, the value will be between 0 and 1, but may be negative in the case of particularly dilapidated models.<br><br>\n",
    "The default strategy of *DummyRegressor* is to predict the average value of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b32aaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03469753992352409"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr = DummyRegressor()\n",
    "\n",
    "dr.fit(bos_X_train, bos_y_train)\n",
    "\n",
    "dr.score(bos_X_test, bos_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f621f1",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "A simple **linear regression** tries to adapt the formula *y = mx + b*, while minimizing the square of errors. When applied, we have an *intercept* and a *coefficient*. <br><br>\n",
    "The *intercept* provides a base value for a prediction, modified by the sum of the product between the coefficient and the input data. This format can be generalized to larger dimensions. In this case, each attribute will have a coefficient. The higher the absolute value of the coefficient, the more impact the attribute will have on the target.<br><br>\n",
    "This model assumes that the prediction is a linear combination of the input data. For some datasets this would not be enough. More complexity can be added through attribute transformation (**sklearn**'s *preprocessing.PolynomialFeatures* transformer is capable of creating polynomial combinations of attributes). If this results in overfitting, **ridge** and **lasso** regressions can be used to regularize the estimator.<br><br>\n",
    "This model is also susceptible to *heteroscedasticity*. *Heteroscedasticity* is the idea that as input values change, so does the prediction error (or residuals). Another issue that must be considered is *multicollinearity*. That is, if the columns have a high level of correlation, it will be more difficult to interpret the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496a35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
